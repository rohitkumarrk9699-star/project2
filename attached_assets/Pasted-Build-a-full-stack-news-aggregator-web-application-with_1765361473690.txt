Build a full-stack news aggregator web application with live web scraping. The backend should have an API endpoint that scrapes 20 trending articles per category (International, Sports, Technology, Health, Science) from real news websites using Cheerio and Axios. Each article must include: title, 2-page detailed content, unique image URL from the source, source name, and clickable source link. No database - all data is scraped fresh on every request. The frontend should be a modern, responsive React app with category pages, article cards showing source attribution, and detailed article pages with "Read Original Source" buttons. Use Tailwind CSS for styling with a clean editorial design. Every page refresh should trigger new scraping with no caching. ðŸ“‹ Complete Project Specification: LiveBuzz - Live News Aggregator Project Overview A fully responsive, full-stack blog web application that performs live web scraping to fetch the top 20 latest/trending news items from multiple categories. The application has no database - all content is scraped fresh in real-time on every request. Categories International Sports Technology Healthy Life Science Technology Stack: Backend Architecture Node.js + Express.js Cheerio (HTML parsing) Axios (HTTP requests) TypeScript API Endpoints: Endpoint	Method	Description /api/scrape/:category	GET	Scrapes 20 articles from the specified category /api/scrape-all	GET	Scrapes all categories in parallel /api/health	GET	Health check endpoint and so one Scraping Sources: International â†’ Reuters World News National -> Indian news & India Sports â†’ all sports ESPN Technology â†’ TechCrunch Healthy Life â†’ Healthline and style Science â†’ Science and technoloy Data Structure (per article): { id: string,           // Unique identifier title: string,        // Scraped headline summary: string,      // Short description (300 chars) content: string,      // Full 2-page HTML article (~1000-1500 words) category: string,     // Category name author: string,       // Source name readTime: string,     // e.g., "5 min read" date: string,         // ISO timestamp imageUrl: string,     // Unique image from original source tags: string[],       // Extracted keywords sourceName: string,   // e.g., "Reuters", "ESPN" sourceUrl: string     // Clickable link to original article } Key Backend Rules: No database storage No caching - every request performs fresh scraping Detailed 2-page content auto-generated for each article Images extracted directly from source websites All data exists only in memory for the current request Frontend Architecture Technology Stack: React 19 TypeScript TanStack Query (data fetching) Wouter (routing) Tailwind CSS v4 Shadcn/UI components Framer Motion (animations) Pages: Home (/) - Featured hero section, category grids, latest updates sidebar Category (/category/:name) - Grid of 20 articles per category Post (/post/:id) - Full article detail page with 2-page content UI Features: Modern "Editorial Pop" design aesthetic Typography: Outfit (headings) + Inter (body) Responsive mobile-first layout Smooth page transitions and hover animations Search functionality in header Newsletter subscription section Trending sidebar Source attribution badges on every card Data Display (per card): âœ… Title from scraped source âœ… Summary/description âœ… Unique image (no placeholders) âœ… Source name badge âœ… Clickable source link âœ… Read time âœ… Category tag Key Behaviors Fresh Content on Every Load: staleTime: 0 - data is never considered fresh refetchOnMount: true - always fetches on page load refetchOnWindowFocus: true - refetches when user returns No History/Storage: No database No localStorage No session persistence Content exists only during the current browser session Real-Time Scraping: Backend performs live HTTP requests to news sources Parses HTML with Cheerio Extracts: titles, links, images, summaries Generates detailed article content Returns JSON to frontend